{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT  - This is a Boosted Decision Tree example using SciKit Learn\n",
    "\n",
    "    Copyright (C) 2020 Adrian Bevan, Queen Mary University of London\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "    \n",
    "----------------------\n",
    "##Â Boosted Decision Trees\n",
    "\n",
    "Decision trees are weak learners. The method of boosting was introduced in order to allow an ensemble of weak learners to be used in a classification or regression problem. The ensemble of weak learners tends to be a strong learner, and is less susceptible to over training. This notebook will use the iris data used in the paper by R. A. Fisher \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936).  The Boosting algorithm used by this example is the Adaptive Boost (or AdaBoost).  This classifier is described in more detail on the sklearn website: [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). \n",
    "\n",
    "The data are split into test and train samples, and the classifier is learned on the train sample. The residual test sample is then used to evaluate the performance of the classifier learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLoad the sklearn Iris data\u001b[0m\n",
      "\n",
      "Iris data have been split into test and train samples\n",
      "\tN(train) =  112\n",
      "\tN(test)  =  38\n",
      "\u001b[1mFit the decision tree\u001b[0m\n",
      "... now compute the decision tree score\n",
      "\n",
      "Decision Tree Classifier Score is:\n",
      "\tTrain Score =  0.9375  (This measure of performance is biased)\n",
      "\tTest Score  = 0.8947\n",
      "\tNumber of mis-classified test data = 4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Parameters\n",
    "n_classes = 3\n",
    "plot_colors = \"ryb\"\n",
    "plot_step = 0.01\n",
    "\n",
    "# Load data\n",
    "print(\"\\033[1mLoad the sklearn Iris data\\033[0m\\n\")\n",
    "iris = load_iris()\n",
    "\n",
    "# split the data into test and train samples. The train sample will be used to learn\n",
    "# the model, and the test sample will be used to evaluate module performance.\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "print(\"Iris data have been split into test and train samples\")\n",
    "print(\"\\tN(train) = \", len(X_train))\n",
    "print(\"\\tN(test)  = \", len(X_test))\n",
    "\n",
    "\n",
    "print(\"\\033[1mFit the decision tree\\033[0m\")\n",
    "BDT_clf = AdaBoostClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "print(\"... now compute the decision tree score\")\n",
    "train_score = BDT_clf.score(X_train, y_train)\n",
    "test_score  = BDT_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier Score is:\")\n",
    "print(\"\\tTrain Score = \", train_score, \" (This measure of performance is biased)\")\n",
    "print(\"\\tTest Score  = {:5.4f}\".format(test_score))\n",
    "print(\"\\tNumber of mis-classified test data = {:2.1f}\".format((1-test_score)*len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "## Evaluating the model\n",
    "\n",
    "Having learned the classification model we can now apply this to the test data. This is done by using the model to predict an output given the input data examples. Those predicted classification labels can be compared against the true values on an individual basis and via a confusion matrix (a $2\\times 2$ matrix of ground truth vs model predictions, where the off-diagonal terms are mis-clasified examples).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mStudy the test data\u001b[0m\n",
      "\n",
      "confusion matrix (test) = \n",
      " [[13  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  4  5]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mCheck ground truth against predictions for the test sample\u001b[0m\n",
      "Truth\tPrediction\tCorrect Prediction\n",
      "2\t2\tTrue\n",
      "1\t1\tTrue\n",
      "0\t0\tTrue\n",
      "2\t2\tTrue\n",
      "0\t0\tTrue\n",
      "2\t2\tTrue\n",
      "0\t0\tTrue\n",
      "1\t1\tTrue\n",
      "1\t1\tTrue\n",
      "1\t1\tTrue\n",
      "2\t1\tFalse\n",
      "1\t1\tTrue\n",
      "1\t1\tTrue\n",
      "1\t1\tTrue\n",
      "1\t1\tTrue\n",
      "0\t0\tTrue\n",
      "1\t1\tTrue\n",
      "1\t1\tTrue\n",
      "0\t0\tTrue\n",
      "0\t0\tTrue\n",
      "2\t1\tFalse\n",
      "1\t1\tTrue\n",
      "0\t0\tTrue\n",
      "0\t0\tTrue\n",
      "2\t1\tFalse\n",
      "0\t0\tTrue\n",
      "0\t0\tTrue\n",
      "1\t1\tTrue\n",
      "1\t1\tTrue\n",
      "0\t0\tTrue\n",
      "2\t2\tTrue\n",
      "1\t1\tTrue\n",
      "0\t0\tTrue\n",
      "2\t1\tFalse\n",
      "2\t2\tTrue\n",
      "1\t1\tTrue\n",
      "0\t0\tTrue\n",
      "1\t1\tTrue\n",
      "\n",
      "\u001b[1mRun Cross Validation On the Sample\u001b[0m\n",
      "cross validation scores =  [0.91666667 0.95652174 1.         0.86363636 0.95238095]\n",
      "\tmean = 0.9378\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Use the test data to compute a confusion matrix and to compare predictions against\n",
    "# the ground truth labels.\n",
    "#\n",
    "print(\"\\n\\033[1mStudy the test data\\033[0m\")\n",
    "predictions = BDT_clf.predict(X_test)\n",
    "BDTcm = confusion_matrix(y_test, predictions)\n",
    "print(\"\\nconfusion matrix (test) = \\n\", BDTcm)\n",
    "sns.heatmap(BDTcm, center=True)\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "# Compare the ground truth and model prediction\n",
    "#\n",
    "\n",
    "print(\"\\n\\033[1mCheck ground truth against predictions for the test sample\\033[0m\")\n",
    "print(\"Truth\\tPrediction\\tCorrect Prediction\")\n",
    "for i in range(len(predictions)):\n",
    "    Match = False\n",
    "    if predictions[i] == y_test[i]:\n",
    "        Match = True\n",
    "    print(\"{:}\\t{:}\\t{:}\".format(y_test[i], predictions[i], Match))\n",
    "\n",
    "#\n",
    "# Try cross validation with this sample - 5 splits of the data.  For this \n",
    "# look at the accuracy scores for each split in order to determine the\n",
    "# mean performance.\n",
    "#\n",
    "print(\"\\n\\033[1mRun Cross Validation On the Sample\\033[0m\")\n",
    "scores = cross_val_score(BDT_clf, X_train, y_train, cv=5)\n",
    "print(\"cross validation scores = \", scores)\n",
    "print(\"\\tmean = {:5.4f}\".format(scores.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
